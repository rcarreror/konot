\section{Contexto y motivación}
    El aumento del número de dispositivos \textit{IoT} conectados a las redes de computadores (incrementando el número de datos que se envían por estas) y la aparición de nuevas tecnologías como los videojuegos en la nube o \textit{cloud gaming}, y el "meta-verso" (que necesitan un envío y recepción de gran cantidad de datos a una alta velocidad), requerirá unas infraestructuras de red que aseguren una buena calidad de experiencia (\textit{QoE}) a los usuarios. Para ello es necesario estudiar e investigar, como se hace en este proyecto, las causas de la latencia para poder mejorar las redes ya existentes y tenerlo en cuenta en las futuras.
  
    Con el objetivo de conseguir una menor latencia, es necesario entender que un mayor ancho de banda, no siempre significa siempre una mayor velocidad de transferencia, o una menor latencia. Tiene sentido aumentar el ancho de banda, por ejemplo, cuando lo que se necesita es enviar datos o paquetes de "gran tamaño". Sin embargo, en las aplicaciones que requieran enviar y recibir datos de "pequeño tamaño", aumentar el ancho de banda por encima de los 100Mbps (Mega-bits por segundo) no significará una disminución notable de la latencia. En 2022, un 84,96\%  de los usuarios en España ya disponían de un ancho de banda alto, mayor a 1Gbps (Giga-bits por segundo), por lo que reducir el retraso en el tiempo de transmisión ya no supone una necesidad tan grande como antiguamente. Ya que se utilizan servidores descentralizados y redes de distribución de contenido, el retraso en el tiempo propagación se ha reducido mayormente. Por lo tanto, podemos centrarnos en solucionar aspectos relacionados con el equipamiento de red (enrutadores, conmutadores, tarjetas de red...), tales como el tiempo de procesamiento y el retardo de colas.

    A la hora de realizar pruebas de red, para alcanzar conclusiones útiles, se deben considerar ciertas cuestiones, como son la carga de la red, las medidas que se toman y el estudio de estas. Si se realizan las pruebas en una red en condiciones óptimas (de baja carga de transmisión de datos), normalmente, se obtienen resultados de latencia mucho menores que los que se obtendrían en una red sobrecargada. Ya que las situaciones en las que la latencia afecta más a la experiencia de usuario son en redes sobrecargadas, se tendría una imagen incompleta y menos útil del funcionamiento de la red. Al igual que si se estudia únicamente la media de los datos de latencia, en lugar de los valores máximos o el percentil 99 superior de estos. Finalmente, si sólo se toma la medida de tiempo de ida y vuelta (usualmente llamado \textit{RTT}), no se tendría en cuenta la información que proporciona la variación del retardo (usualmente llamado \textit{jitter}) o la pérdida de paquetes, las cuales influyen mucho en la QoE del usuario. En conclusión, a la hora de asegurar requisitos mínimos al usuario o cliente, no se tendrían en cuenta escenarios en los que la latencia es realmente un problema, pudiendo ocasionar que un jugador profesional de videojuegos pierda una partida o errores en una intervención quirúrgica telemática.